{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Конфигурация**\n",
    "\n",
    "Здесь осуществялется **указание переменных проекта**, **подключение всех импортов**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты\n",
    "\n",
    "Здесь осуществляется импорт всех используемых в проекте библиотек. **Все импорты следует указывать здесь**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random, shutil, ntpath, cv2, pandas as pd, tensorflow as tf\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from google.colab import drive\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение данных\n",
    "\n",
    "Здесь осуществляется подключение данных. Данными выступают фотографии. Фотографии берутся из Google Disk. Исходя из своих потребностей **вы можете сами определить для себя, откуда вы будете извлекать фотографии для формирования датасетов**. Это означает, что вам не обязательно выполнять данный блок, но придется переопределить его для своих нужд и возможностей, например, осуществляя локальную подгрузку файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подключение вашего гугл диска\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции\n",
    "\n",
    "Здесь определяются функции, которые могут быть использованы во всех последующих блоках многократно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подгрузки всех файлов\n",
    "def get_files_from(path, exp):\n",
    "\n",
    "  images = []\n",
    "\n",
    "  for f in glob.glob(\"drive/MyDrive/csu/ML/\" + path + \"/\" + \"*.\" + exp):\n",
    "\n",
    "    images.append(f)\n",
    "\n",
    "  return images\n",
    "\n",
    "# копирование файлов в указанную директорию\n",
    "def copy_files_from(path, files):\n",
    "\n",
    "  for f in files:\n",
    "\n",
    "    shutil.copyfile(f, \"drive/MyDrive/csu/ML/\" + path + \"/\" + ntpath.basename(f))\n",
    "\n",
    "# удаление всех файлов в директории\n",
    "def remove_files_from(path):\n",
    "\n",
    "  for f in glob.glob(\"drive/MyDrive/csu/ML/\" + path + \"/**/*\", recursive = True):\n",
    "\n",
    "    try:\n",
    "      \n",
    "      os.remove(f)\n",
    "    \n",
    "    except OSError as e:\n",
    "\n",
    "      print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переменные\n",
    "\n",
    "Здесь определяются переменные проекта, которые будут использоваться во всех последующих блоках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кол-во эпох\n",
    "epochs = 100\n",
    "# ширина изображений\n",
    "img_width = 224\n",
    "# высота изображений\n",
    "img_height = 224\n",
    "# кол-во изображений\n",
    "img_count = 640\n",
    "# размеры изображения\n",
    "img_size = (img_width, img_height, 3)\n",
    "# размер пакета\n",
    "batch_size = 32\n",
    "# кол-во классов\n",
    "num_classes = 2\n",
    "# названия классов\n",
    "class_names = [\"Olds\", \"Youngs\"]\n",
    "# цвет\n",
    "color_mode = \"rgb\"\n",
    "# шаг валидации\n",
    "validation_steps = 30\n",
    "# основная директория\n",
    "dir_main = Path(\"drive/MyDrive/csu/ML\")\n",
    "# пути к фотографиям старцев\n",
    "class1 = get_files_from(\"Olds\", \"jpg\")\n",
    "# пути к фотографиям юнцов\n",
    "class2 = get_files_from(\"Youngs\", \"jpg\")\n",
    "# массив всех изображений\n",
    "images = class1 + class2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Обработка данных**\n",
    "\n",
    "Здесь осуществляется обработка данных, перед формированием наборов данных. Их можно искажать, подгонять под правильные размеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменение размеров изображений\n",
    "\n",
    "Здесь осуществялется изменение размеров всех фотографий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in images:\n",
    "  \n",
    "  Image.open(f).resize((img_width, img_height)).save(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Формирование данных**\n",
    "\n",
    "Здесь осуществялется формирование наборов данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Очистка предыдущих наборов данных\n",
    "\n",
    "Здесь осуществялется очистка всех фотографий из папок преназначенных для формирования наборов данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление тренировочной папки\n",
    "remove_files_from(\"Train/Olds\")\n",
    "remove_files_from(\"Train/Youngs\")\n",
    "# удаление валидационной папки\n",
    "remove_files_from(\"Validate/Olds\")\n",
    "remove_files_from(\"Validate/Youngs\")\n",
    "# удаление тестовой папки\n",
    "remove_files_from(\"Test/Olds\")\n",
    "remove_files_from(\"Test/Youngs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполнение папок наборов данных\n",
    "\n",
    "Здесь формируются папки будущих наборов данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполнение тренировочной папки\n",
    "copy_files_from(\"Train/Olds\", class1[:(int)(len(class1)*0.7)])\n",
    "copy_files_from(\"Train/Youngs\", class2[:(int)(len(class2)*0.7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполнение валидационной папки\n",
    "copy_files_from(\"Validate/Olds\", class1[(int)(len(class1)*0.7):(int)(len(class1)*0.85)])\n",
    "copy_files_from(\"Validate/Youngs\", class2[(int)(len(class2)*0.7):(int)(len(class2)*0.85)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполнение тестовой папки\n",
    "copy_files_from(\"Test/Olds\", class1[(int)(len(class1)*0.85):])\n",
    "copy_files_from(\"Test/Youngs\", class2[(int)(len(class2)*0.85):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание наборов данных\n",
    "\n",
    "Здесь осуществляется формирование наборов данных, как объектов tf. Для формирования используется подгрузка данных из папок. **Формировать такие наборы следует в отдельных блоках**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание тренировочного датасета\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"drive/MyDrive/csu/ML/Train/\",\n",
    "  seed=123,\n",
    "  shuffle=True,\n",
    "  subset=\"validation\",\n",
    "  color_mode=color_mode,\n",
    "  class_names = class_names,\n",
    "  batch_size=batch_size,\n",
    "  image_size=img_size[:2],\n",
    "  validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание валидационного датасета\n",
    "validate_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"drive/MyDrive/csu/ML/Validate/\",\n",
    "  seed=123,\n",
    "  shuffle=True,\n",
    "  subset=\"validation\",\n",
    "  color_mode=color_mode,\n",
    "  class_names = class_names,\n",
    "  batch_size=batch_size,\n",
    "  image_size=img_size[:2],\n",
    "  validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание таблиц\n",
    "\n",
    "Здесь осущетсвялется формирование таблиц на основе наборов данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тренировочный датафрейм\n",
    "set_training = [(file.as_posix(), file.parent.name) for file in dir_main.joinpath(\"Train\").glob(\"**/*.*\")]\n",
    "train_df = pd.DataFrame(data=set_training, columns=['file', 'label'])\n",
    "train_df['label_i'] = train_df['label'].astype('category').cat.codes\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# валидационный датафрейм\n",
    "set_validate = [(file.as_posix(), file.parent.name) for file in dir_main.joinpath('Validate').glob('**/*.*')]\n",
    "val_df = pd.DataFrame(data=set_validate, columns=['file', 'label'])\n",
    "val_df['label_i'] = val_df['label'].astype('category').cat.codes\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Формирование Модели**\n",
    "\n",
    "Здесь осуществляется формирование модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели на основе наборов данных\n",
    "model = Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=img_size),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Компиляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Обучение Модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=validate_ds,\n",
    "    validation_steps=validation_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
